{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_path = \"/Volumes/External/datasets/Recommendation/MovieLens/ml-20m/ratings-1m.csv\"\n",
    "titles_path = \"/Volumes/External/datasets/Recommendation/MovieLens/ml-20m/movies.csv\"\n",
    "\n",
    "titles = pd.read_csv(titles_path).drop('genres', axis=1)\n",
    "data = pd.read_csv(ratings_path).drop('timestamp', axis=1)\n",
    "data_clean = data.groupby('movieId').filter(lambda x: len(x) >= 20).groupby('userId').filter(lambda x: len(x) >= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = data_clean['userId'].nunique()\n",
    "n_movies = data_clean['movieId'].nunique()\n",
    "tr_ratings = np.zeros((n_users, n_movies))\n",
    "te_ratings = np.zeros((n_users, n_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mask = np.random.rand(len(data_clean)) < 0.8\n",
    "train = data_clean[split_mask]\n",
    "test = data_clean[~split_mask]\n",
    "tr_n_pairs = train.shape[0]\n",
    "te_n_pairs = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id, old_id = zip(*enumerate(data_clean['movieId'].unique()))\n",
    "old_m2new = dict(zip(old_id, new_id))\n",
    "new_id, old_id = zip(*enumerate(data_clean['userId'].unique()))\n",
    "old_u2new = dict(zip(old_id, new_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(ratings):\n",
    "    mask = np.zeros_like(ratings)\n",
    "    mask[np.where(ratings!=0.)] = 1.\n",
    "    return mask\n",
    "\n",
    "def construct_rating_matr(data, n_users, n_items):\n",
    "    ratings = np.zeros((n_users, n_movies))\n",
    "    np_data = data.values\n",
    "    userId = np.vectorize(lambda x: old_u2new[x])(np_data[:,0])\n",
    "    movieId = np.vectorize(lambda x: old_m2new[x])(np_data[:,1])\n",
    "    ratings_val = np_data[:,2]\n",
    "    ratings[userId, movieId] = ratings_val\n",
    "    return ratings, create_mask(ratings)\n",
    "\n",
    "def construct_rating_matr_sp(data, n_users, n_items):\n",
    "    np_data = data.values\n",
    "    userId = np.vectorize(lambda x: old_u2new[x])(np_data[:,0])\n",
    "    movieId = np.vectorize(lambda x: old_m2new[x])(np_data[:,1])\n",
    "    ratings_val = np_data[:,2]\n",
    "    ratings = coo_matrix((ratings_val, (userId, movieId)), shape=(n_users, n_items))\n",
    "    return ratings, userId, movieId\n",
    "\n",
    "# tr_ratings, tr_mask = construct_rating_matr_sp(train)\n",
    "# te_ratings, te_mask = construct_rating_matr_sp(test)\n",
    "tr_ratings, tr_users, tr_movies = construct_rating_matr_sp(train, n_users, n_movies)\n",
    "te_ratings, te_users, te_movies = construct_rating_matr_sp(test, n_users, n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom_rank = 100\n",
    "l = 2.\n",
    "lr_decay = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ratings(users_m, movies_m):\n",
    "    return users_m @ movies_m.T\n",
    "\n",
    "def estimate_ratings_sp(users_m, movies_m, userId, movieId, shape): \n",
    "    inner = np.sum(users_m[userId] * movies_m[movieId], axis=1)\n",
    "    return coo_matrix((inner, (userId, movieId)), shape=shape)\n",
    "\n",
    "def error(pred, true):\n",
    "    return pred - true \n",
    "\n",
    "def apply_mask(error, mask):\n",
    "    return np.multiply(error, mask)\n",
    "\n",
    "def gradient_sp(users_m, movies_m, gradients_for, l, true_r, total_ratings, userId, movieId):\n",
    "    pred_r = estimate_ratings_sp(users_m, movies_m, userId, movieId, true_r.shape)\n",
    "    err = error(pred_r, true_r)\n",
    "    \n",
    "    if gradients_for=='u':\n",
    "        grad = err @ movies_m + l * users_m\n",
    "    elif gradients_for=='m':\n",
    "        grad = err.T @ users_m + l * movies_m\n",
    "        \n",
    "    return grad / total_ratings\n",
    "\n",
    "def gradient(users_m, movies_m, gradients_for, l, mask, true_r, total_ratings):\n",
    "    pred_r = estimate_ratings(users_m, movies_m)\n",
    "    err = error(pred_r, true_r)\n",
    "    m_err = apply_mask(err, mask)\n",
    "    \n",
    "    if gradients_for=='u':\n",
    "        grad = m_err @ movies_m + l * users_m\n",
    "    elif gradients_for=='m':\n",
    "        grad = m_err.T @ users_m + l * movies_m\n",
    "        \n",
    "    return grad / total_ratings\n",
    "\n",
    "def rmse_sp(users_m, movies_m, l, true_r, userId, movieId, total_ratings):\n",
    "    pred_r = estimate_ratings_sp(users_m, movies_m, userId, movieId, (users_m.shape[0], movies_m.shape[0]))\n",
    "    err = error(pred_r, true_r)\n",
    "    return np.sqrt(err.power(2).sum()/total_ratings)\n",
    "\n",
    "def rmse(users_m, movies_m, l, mask, true_r, total_ratings):\n",
    "    pred_r = estimate_ratings(users_m, movies_m)\n",
    "    err = error(pred_r, true_r)\n",
    "    m_err = apply_mask(err, mask)\n",
    "    return np.sqrt(np.sum(np.square(m_err))/total_ratings)\n",
    "\n",
    "def loss(users_m, movies_m, l, mask, true_r, total_ratings):\n",
    "    pred_r = estimate_ratings(users_m, movies_m)\n",
    "    err = error(pred_r, true_r)\n",
    "    m_err = apply_mask(err, mask)\n",
    "    \n",
    "    return rmse(users_m, movies_m, l, mask, true_r, total_ratings) + l * (np.linalg.norm(users_m) + np.linalg.norm(movies_m))\n",
    "    \n",
    "# rating_estimate_masked = lambda users, movies, mask: np.multiply(np.matmul(users, movies.T), mask)\n",
    "# error_est = lambda true, pred:  pred - true\n",
    "# gradient = lambda error, weights_to_upd, weights_other, l: 1 / tr_n_pairs * np.matmul(error, weights_other) + l * weights_to_upd\n",
    "# loss = lambda user, movies, l, ratings, mask: 1 / te_n_pairs * np.sum(np.square(ratings - rating_estimate_masked(user, movies, mask))) + \\\n",
    "# l * (np.linalg.norm(user_m) + np.linalg.norm(item_m))\n",
    "# grad_u = lambda user, movies, l: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient(user_m, item_m, 'm', l, tr_mask, tr_ratings, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(max_iter):\n",
    "#     user_m = user_m - lr * gradient(error_est(tr_ratings, rating_estimate_masked(user_m, item_m, tr_mask)), user_m, item_m, l)\n",
    "#     item_m = item_m - lr * gradient(error_est(tr_ratings, rating_estimate_masked(user_m, item_m, tr_mask)).T, item_m, user_m, l)\n",
    "#     print(loss(user_m, item_m, l, te_ratings, te_mask))\n",
    "#     lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dense\n",
    "# user_m = np.random.rand(n_users, decom_rank)\n",
    "# item_m = np.random.rand(n_movies, decom_rank)\n",
    "# lr = 100.0\n",
    "# max_iter = 20\n",
    "# for i in range(max_iter):\n",
    "#     user_m = user_m - lr * gradient(user_m, item_m, 'u', l, tr_mask, tr_ratings, tr_n_pairs)\n",
    "#     item_m = item_m - lr * gradient(user_m, item_m, 'm', l, tr_mask, tr_ratings, tr_n_pairs)\n",
    "#     print(rmse(user_m, item_m, l, te_mask, te_ratings, te_n_pairs))\n",
    "#     lr *= lr_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.815928199704476\n",
      "18.726530573841625\n",
      "10.194006230115287\n",
      "5.128840004312524\n",
      "4.066408959138058\n",
      "3.5039479091360723\n",
      "3.138158061988774\n",
      "2.8766485113722022\n",
      "2.6779690772670817\n",
      "2.5199820889182423\n",
      "2.389864446409499\n",
      "2.2799808297583124\n",
      "2.185685949575921\n",
      "2.103975841860823\n",
      "2.0327041444012166\n",
      "1.9701907712206839\n",
      "1.9150531920290406\n",
      "1.8661348365752142\n",
      "1.8224688045063389\n",
      "1.7832506032668354\n"
     ]
    }
   ],
   "source": [
    "user_m = np.random.rand(n_users, decom_rank)\n",
    "item_m = np.random.rand(n_movies, decom_rank)\n",
    "lr = 100.0\n",
    "max_iter = 10\n",
    "for i in range(max_iter):\n",
    "    user_m = user_m - lr * gradient_sp(user_m, item_m, 'u', l, tr_ratings, tr_n_pairs, tr_users, tr_movies)\n",
    "    item_m = item_m - lr * gradient_sp(user_m, item_m, 'm', l, tr_ratings, tr_n_pairs, tr_users, tr_movies)\n",
    "    print(rmse_sp(user_m, item_m, l, te_ratings, te_users, te_movies, te_n_pairs))\n",
    "    lr *= lr_decay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
